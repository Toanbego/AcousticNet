## PARAMETERS

[preprocessing]
; Feature parameters:
;       n_fft: Number of fourier transforms executed over the audio sample
;       n_feat: Number of cepstral coefficients extracted from the filterbanks
;       n_filt: Number of filterbanks calculated from the power spectrums
;
NOTE:   For the parameter changes to have an effect, use audio_folder = augmented. If using img, then the audio files
        have been pre-extracted with a givens et of parameters:
        (n_fft=1200, n_feat=13, n_filt=26, threshold=0.005, delta=False, rate=16000)

csv_file = C:\Users\toanb\OneDrive\skole\UiO\Master\Datasets\UrbanSound8K\metadata\UrbanSound8K_augmented_v3.csv
classes =
;            children_playing,
            air_conditioner,
            engine_idling,
;            siren,
;            street_music,
;            drilling,
            jackhammer,
;            dog_bark,
;            gun_shot,
            car_horn,

two_class =
# Minimum length of audio files to extract from. Given in seconds
signal_minimum_length = 0.1
feature = spectogram
;audio_folder = img
audio_folder = img
activate_thresholding = False
threshold = 0.005
n_fft = 1200
n_feat = 13
n_filt = 26
precision = 10
delta_delta = False
random_extraction = False
use_grayscale = False
# The length of the sample extracted from audio file. Must be smaller than signal length
step_size = 0.1
# For scalograms, use percentages of full clip instead of seconds. They are all yhe same size. So this will
# make a random slice of x% of the file.
step_size_scalogram = 0.75
rate = 16000

[augmentation]
; Add the augmentations which will be randomly applied with a uniform distribution
augmentations =
# time_shift
# Possible params are 0.85, 1.2
time_shift_param = 0.85, 1.2
# Possible params are -2, 2
pitch_shift_param = -2, 2
noise_factor = 0.001
test_augmentation = True
augmentation = time_shift

[model]
; Modes:
;       'save_features': Extracts random features from the data set
;       'train_network': Loads features and starts training the network
;       'test_network': Test a network based on a trained model
network_mode = train_network
network_architecture = novel_cnn
; List of currently available networks architectures:
;   novel_cnn
;   novel_cnn_asym
;   novel_cnn_small_kernels
;   d_cnn
;   novel_cnn_bn
no_test_fold = True
# This puts the test fold into the training set. Performance is then measured by the validation set only.

# Generates batches instead of using pre-made features. Set to True then specify path
load_weights = False
load_model = C:\Users\toanb\OneDrive\skole\UiO\Master\code\experiments_results\three_classes_cont\spectogram2\weights.15-0.76_spectogram_fold5.hdf5
weights =
        C:\Users\toanb\OneDrive\skole\UiO\Master\code\experiments_results\three_classes_cont\spectogram2\weights.15-0.76_spectogram_fold5.hdf5,
        C:\Users\toanb\OneDrive\skole\UiO\Master\code\experiments_results\three_classes_cont\scalogram\weights.63-0.79_scalogram_fold5.hdf5,
        C:\Users\toanb\OneDrive\skole\UiO\Master\code\experiments_results\three_classes_cont\msfb\weights.48-0.64_msfb_fold5.hdf5,
        C:\Users\toanb\OneDrive\skole\UiO\Master\code\experiments_results\three_classes_cont\librosa\weights.34-0.82_librosa_fold5.hdf5,
        C:\Users\toanb\OneDrive\skole\UiO\Master\code\experiments_results\three_classes_cont\mfcc\weights.149-0.59_mfcc_fold5.hdf5,


test_mode = test_all


# Hyperparameters
fold = 5
randomize_roll = False
learning_rate = 0.001
batch_size = 64
epochs = 50
optimizer = adam

# Tools:
; tensorboard --logdir=logs --host localhost --port 8088
; pip install pywavelets python_speech_features muda jams tqdm resampy sklearn pandas matplotlib
; conda install keras-gpu opencvpython
; [^\x00-\x7f]
;print('mu: \u03BC')




