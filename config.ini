## PARAMETERS
[preprocessing]
# Feature parameters:
#       n_fft: Number of fourier transforms executed over the audio sample
#       n_feat: Number of cepstral coefficients extracted from the filterbanks
#       n_filt: Number of filterbanks calculated from the power spectrums

# Minimum length of audio files to extract from. Given in seconds
signal_minimum_length = 3
feature = logfbank
activate_thresholding = True
threshold = 0.005
n_fft = 1500
n_feat = 13
n_filt = 26
delta_delta = False
random_extraction = True
# pip install pywavelets python_speech_features muda jams tqdm resampy sklearn pandas matplotlib
# conda install keras-gpu opencvpython tra
# The length of the sample extracted from audio file. Must be smaller than signal length
step_size = 3
rate = 16000
# tensorboard --logdir=logs --host localhost --port 8088
audio_folder = augmented

[augmentation]
# Add the augmentations which will be randomly applied with a uniform distribution
augmentations =
time_shift = False
# Possible params are 0.85, 1.2
time_shift_param = 0.85, 1.2
pitch_shift = False
# Possible params are -2, 2
pitch_shift_param = -2, 2

[model]
# Modes:
#       'save_features': Extracts random features from the data set
#       'train_network': Loads features and starts training the network
#       'test_network': Test a network based on a trained model
network_mode = train_network
network_architecture = novel_net
# List of currently available networks architectures:
#   novel_net
#   novel_net_small_kernels
#   bigger_net

# Generates batches instead of using pre-made features. Set to True then specify path
load_weights = False
load_model = weights\weights.60-0.89_spectogram_fold10.hdf5
test_mode = test_all

# Hyperparameters
fold = 10
randomize_roll = False
learning_rate = 0.001
batch_size = 32
epochs = 100
optimizer = adam





